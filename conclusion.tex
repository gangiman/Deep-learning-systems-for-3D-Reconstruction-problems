\chapter{Conclusion}

In this work, three important aspects of building deep learning systems for human recognition are addressed: the architecture design, the objective function design and deep domain adaptation techniques. Most of the results demonstrated in the work are for person re-identification;  cross-domain learning has been also considered for surveillance face recognition.

A new loss function, called the Histogram loss, for learning deep embeddings using siamese neural networks has been suggested in this work. Like many other existing loss functions, it encourages higher similarity values for semantically related examples, and lower similarity values for unrelated examples. Unlike other loss functions that are computed for tuples of descriptors (\eg{} pairs), the suggested loss is computed for two one-dimensional distributions of similarity values: one is for similarity values for \textit{positive} (matching) pairs of embeddings, and another is for similarity values for \textit{negative} (non-matching) pairs. The goal of this loss function is to reduce the overlap between such distributions, which results in higher similarity values for positive pairs compared to those for negative pairs. Experiments have shown that such loss performs favorably for a range of problems, including person re-identification for CUHK03 and Market-1501 datasets, retrieval of bird species  for the CUB-200-2011 dataset and online products for the Stanford Online Products dataset. Notably, the performance of the Histogram loss has appeared to be the best for person re-identification among several losses based on tuples. In more detail, for person re-identification, it outperformed well-tuned pairwise Binomial Deviance loss \eq{bindev} and the Lifted Structured Similarity Softmax loss \eq{lifted}, that is biased to hard negative examples.

A person re-identification architecture, called Multi-region Bilinear CNN, is also presented in this work. It is based on the idea of Bilinear CNNs that learn deep representations in a factorized form: 
an outer product of two stacks of feature maps is computed for each spatial location, followed by global sum-pooling. Such architectures are able to model non-rigid transformations and view-point changes in fine-grained recognition problems, however, such global pooling appears to be too radical for person re-identification. Multi-region Bilinear CNN has been proposed as a certain compromise between Bilinear CNNs and regular CNN architectures that usually consist of convolution layers followed by non-linearity and fully-connected layers. The pooling of bilinear features is performed separately for a set of regions instead of pooling over all the spatial locations. Such modification allows  preserving some spatial information in the output descriptor. The proposed architecture has been shown to perform better than a number of baselines, including Bilinear CNN and a regular CNN, for three popular re-identification datasets: CUHK03, CUHK01 and Market-1501. For the two largest datasets (CUHK03, Market-1501), state-of-the-art results have been achieved (on the moment of publication).

Cross-domain human recognition has also been addressed in this work. For person re-identification, the case of training and testing on disjoint sets of cameras has been considered. Namely, domain-adversarial training approach, also described in \chapt{gradrev}, has been demonstrated to improve the results for cross-domain training, \ie{} when the re-identification siamese neural network is trained and tested using data from different pedestrian datasets. In more detail, domain-adversarial training allows to learn deep representations that are useful for the task of interest (\eg{} classification), and at the same time are domain-invariant. This is achieved by simultaneous training of two predictors: the main task classifier and the binary domain classifier, that predicts to which of the two domains the input data belong. At the same time, the underlying deep representation is trained to minimize the task-specific objective and to maximize the domain prediction loss. For person re-identification, the label predictor is replaced by a descriptor predictor. The experiments show the advantage of using domain-adversarial training for a total of eight domain pairs, where each of the domains corresponds to one of three publicly available person re-identification datasets: VIPER, PRID and CUHK02. %todo check

The challenging case of surveillance face recognition has been also considered. Having a face recognition neural network trained on labeled publicly available data, that are harvested from the Internet and mostly consist of professional photographs, the goal has been to adapt it to unlabeled surveillance data of much lower quality. The domain shift, in this case, is characterized by a complex combination of different degradation factors such as compression, blur, and illumination change. An image-level domain adaptation technique, based on cycle-consistent image-to-image translation model (CycleGAN), has been evaluated and compared to several baselines including domain-adversarial training, also described in \chapt{gradrev}. The image-level translation allows to build two mappings to transfer the images of one domain to the other and vice versa. The approach works in two stages: first, the labeled source data are transferred to the target domain, and then the recognition network is retrained using such transferred data.  The evaluated baselines also include the backward translation from the target surveillance domain to the source Internet domain. Based on performed evaluations and comparisons, a strategy for surveillance face recognition has been suggested. In brief, the most effective approach was to use a mixture of the source Internet data and its version transferred to the surveillance domain.


