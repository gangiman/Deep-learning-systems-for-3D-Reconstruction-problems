\section{Related work}
\label{sect:related}

There are two main research directions dedicated to face recognition for low-quality data: (i) the face restoration approach \cite{pan2014deblurring,TuzelTH16,ZhuLLT16,xu2017learning,huang2017wavelet} and (ii) the domain adaptation approach \cite{gong2012geodesic,huang2007correcting,pan2008transfer,pan2011domain,baktashmotlagh2013unsupervised,long2015learning,luo2018deep,Volpi_2018_CVPR,Hong_2018_CVPR,Deng_2018_CVPR,Bousmalis_2017_CVPR,Murez_2018_CVPR,xu2018cross}.

In the face restoration-based approach, low-quality images are enhanced and restored to facilitate recognition. The ability to reuse existing recognition systems that were developed for high-quality data comes as a natural benefit of such methods. Domain adaptation methods are conversely aimed to change the existing recognition systems so that they are better suited for the target domain (i.e.\ low resolution/quality images). We now provide a brief review of both approaches.

\subsection{Face restoration methods}

There is a vast range of methods that perform face restoration. In most of them, different degradation types are considered separately. Pan \textit{et al.} \cite{pan2014deblurring} propose an effective face deblurring method based on approximating blur kernel followed by non-blind deconvolution. The blur kernel  approximation is guided by the known non-blurred exemplar with the structure similar to the input image structure. 

In Zhang \textit{et al.}~\cite{ZhangYZNH11}, deblurring and recognition tasks are considered simultaneously. They use a sparse representation of the input image in terms of the gallery image set. The blur kernel and representation coefficients are estimated iteratively. Classification is finally performed based on the classes with the highest coefficients in the sparse representation.  


A number of recent methods \cite{TuzelTH16,ZhuLLT16,xu2017learning,huang2017wavelet} explore the task of restoration of extremely low-resolution images using deep neural networks. All these works utilize the paired (aligned) learning scheme, where the high-resolution ground truth is known for every low-resolution image in the training set. The low-resolution training data are simulated using synthetic degradation of the initial high-resolution images. In \cite{xu2017learning} and \cite{TuzelTH16}, a generative adversarial network~(GAN)~\cite{goodfellow2014generative} is used to force the restoration network to produce more natural images. In \cite{huang2017wavelet}, an additional structure-based loss that uses wavelet transform is suggested for the same goal. While the results of these methods are impressive, there is no direct way to use the paired learning approaches for the arbitrary combination of degradation factors that one may encounter when analyzing real images captured by surveillance cameras. 

\subsection{Domain adaptation methods}

Domain adaptation addresses the situation when the source and target data share the same feature space but their distributions differ \cite{wang2018deep}. The latter often causes drop in the performance if the system is trained using only source data and applied to target data.

%non-deep methods
A number of methods estimate the domain distribution difference using Maximum Mean Discrepancy \cite{borgwardt2006integrating} given predefined feature representations: \cite{huang2007correcting,pan2008transfer,pan2011domain,baktashmotlagh2013unsupervised}. Differently from the mentioned methods, \cite{gong2012geodesic} aim at modeling gradual domain transition by embedding source and target domains in a Grassmann manifold.  Similarly, in \cite{xu2018cross}, the authors suggest a domain-adaptive dictionary learning technique to explicitly model a number of intermediate domains using an iterative procedure alternating between regularized sparse coding and dictionary learning. 
%deep

\cite{long2015learning,luo2018deep} incorporate minimization of Maximum Mean Discrepancy into deep learning framework.
Several recent works apply deep adversarial learning techniques in the context of domain adaptation  \cite{Volpi_2018_CVPR,Hong_2018_CVPR,Deng_2018_CVPR,Bousmalis_2017_CVPR,Murez_2018_CVPR}. In \cite{Murez_2018_CVPR}, 
\cite{Bousmalis_2017_CVPR} and \cite{Deng_2018_CVPR}, image-level domain adaptation is performed for segmentation, classification and similarity learning (person re-identification) correspondingly. \cite{Hong_2018_CVPR} and \cite{Volpi_2018_CVPR} suggest domain adaptation at the feature-level for segmentation and classfication tasks. Both feature-level and image-level techniques are used in \cite{Hoffman17}.

Some of the aforementioned methods \cite{Hoffman17,Deng_2018_CVPR,Murez_2018_CVPR} employ CycleGAN framework  to change the domain of training data for classification, segmentation, and person re-identification. Here we explore a similar approach for the task of face recognition in the presence of complex degradation  that  is potentially a result of several factors and is non-trivial to reproduce by some predefined procedure.

Hong \textit{et al.} \cite{HongIRY17} and
Sohn \textit{et al.} \cite{SohnLZY0C17} approach face recognition tasks for low-quality image domain. They consider image degradation as a domain shift and perform feature-level unsupervised domain adaptation based on adversarial learning showing better recognition results. 
The works \cite{HongIRY17} and \cite{SohnLZY0C17} are very related to ours: the authors show that domain-specific data augmentation is essential for training face recognition systems. 
 However, in both works, the data augmentation is performed 'by hand' (the degradation types and hyper-parameters for transforms are chosen and fixed), while we augment the training data in an automatic manner utilizing the CycleGAN framework, which can also be viewed as an image-level domain adaptation.
%Additionally, in contrast to \cite{HongIRY17}, we do not consider extremely large pose variation. Instead, we are more focused on the image degradation factors (e.g. the combination of small size, blur, JPEG-compression). 
Differently from \cite{SohnLZY0C17}, where evaluation is performed for the Youtube faces dataset, we approach the task in the presence of the somewhat stronger domain shift, as our test data are captured by surveillance cameras and are mostly of much lower quality.

\subsection{Surveillance face recognition datasets}

The EK-LFH dataset \cite{HongIRY17} includes $30$ subjects for test with probe images taken in controlled environment and gallery captured by a surveillance camera. 

SCface \cite{grgic2011scface} is another surveillance face dataset. It contains images from 5 indoor surveillance cameras for $130$ subjects in total. One difference from our dataset, besides different illumination conditions and amount of data, is that subjects stopped before each camera to be captured non-moving, so the dataset contain static images.

Differently from both datasets, our evaluation data include images for more subjects: $279$ subjects for test, $96$ subject for validation and $706$ subjects for train. Therefore, our data is probably more suitable for deep learning methods, especially for scenarios implying non-intersecting sets of identities for train and validation data. All the images in our dataset are captured in uncontrolled conditions. 

%SCFace includes images for 130 subjects in total which makes it potentially difficult to apply deep learning methods. 


%Some works already successfully use CycleGAN technique to perform an unsupervised domain adaptation. \cite{CYCADA} approached semantic segmentation. % add avput CYCADA

%recognition and reconstruction approaches
% Several existing works consider restoration and recognition problems jointly. In some works, authors apply the recognition-based priors to achieve better restoration results. \cite{TODO , Xu} 

% There are also approaches jointly performing explicit recognition and restoration
% In \cite{TODO Close  the  loop:  Jointblind  image  restoration  and  recognition  with sparse representation prior , Baker} The  proposed  approaches  perform  recognition  using  a  limited  number  of  gallery  images.   In parallel, they reconstruct the input image and classify it based on labels of the most relevant examples found in the train set.

 
% One of the baselines used in this work applies the similar scheme: CycleGAN framework is used to transfer the low-quality test data into the high-quality domain, the domain classifier serves as 'restoration' loss. We additionally introduce the recognition component into this scheme: another baseline is the same CycleGAN but with domain classifier based that is learned using features calculated with the pre-trained face recognition network.



