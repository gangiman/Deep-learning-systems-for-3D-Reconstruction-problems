\subsection{Introduction}





The task of person re-identification is drawing the ever-increasing attention from the computer vision and the visual surveillance communities. This is because of the inherent difficulty of the task paired with the fact that medium-sized training datasets have become available only recently. The task also has a clear practical value for automated surveillance systems.
Despite a long history of research on re-identification \citep{yi2014deep, ma2012bicov, DBLP:journals/cviu/BazzaniCM13, li2015cross,prosser2010person, kuo2013person,roth2014mahalanobis,hirzer2012person,paisitkriangkrai2015learning,ma2012local,liao2015person,li2014deepreid,ahmed2015improved,chen2015deep}, the accuracy of the existing systems is often insufficient for the full automation of such application scenarios, which stimulates further research activity. The main confounding factor is the notoriously high variation of the appearance of the same person (even at short time spans) due to pose variations, illumination variation, background clutter, complemented by the high number of individuals wearing similar clothes that typically occur in the same dataset.

In this work, we follow the line of work that applies deep convolutional neural networks (CNNs) and embedding learning to the person re-identification task. Our aim is an architecture that can map (embed) an image of a detected person to a high-dimensional vector (descriptor) such that a simple metric such as Euclidean or cosine distance can be applied to compare pairs of vectors and reason about the probability of two vectors to describe the same person. Here, we avoid the approach taken in several recent works \citep{ahmed2015improved} that train a separate multi-layer network to compute the distance between a pair of descriptors, since such methods do not scale well to large datasets, where the ability to perform fast search requires the use of a simple metric.

The choice of the convolutional architecture for embedding in the case of person re-identification is far from obvious. In particular, ``standard'' architectures that combine convolutional layers followed by fully-connected layers such as those used for image classification or face embedding can fail to achieve sufficient invariance to strong 3D viewpoint changes as well as to non-rigid articulations of pedestrians, given the limited amount of training data typical for re-identification tasks and datasets. 

Here, we propose a person re-identification architecture that is based on the idea of bilinear convolutional networks (bilinear CNNs) \citep{lin2015bilinear} that was originally presented for fine-grained classification tasks and later evaluated for face recognition \citep{roychowdhury2015face}. We note that the task of person re-identification shares considerable similarity with fine-grained categorization (\fig{teaser}), as the matching process in both cases often needs to resort to the analysis of fine texture details and parts that are hard to localize.  Bilinear CNNs, however, rather radically discard spatial information in the process of the bilinear pooling. While this may be justified for fine-grained classification problems such as bird classification, the variability of geometric pose and viewpoints in re-identification problems is more restricted. Overall, the multi-region bilinear CNNs can be regarded as a middle ground between the traditional CNNs and the bilinear CNNs. In the experiments, we show that such a compromise achieves an optimal performance across a range of person re-identification benchmarks, while also performing favorably compared to previous state-of-the-art. The success of our architecture confirms the promise hold by deep architectures with multiplicative interactions such as bilinear CNNs and our multi-region bilinear CNNs for hard pattern recognition tasks.

