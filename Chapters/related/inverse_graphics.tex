% !TEX root = ../../Thesis_main.tex
\section{Inverse Graphics}

Inverse graphics approach~\cite{rezende2016unsupervised,eslami2016attend,kulkarni2015deep,Izadinia_2017_CVPR} enables to solve a problem of "real-world" scene understanding through reconstruction of that scene and comparison it to measured data in some form.

Because it's a fairly new method it has some unexplored facets:
\begin{enumerate}
    \item How can we scale to hundreds and thousands of objects with different parameters.
    \item Embedded representations better than procedural generation
    \item Are there format that can have all advantages of CAD models and probabilistic properties that arise from real-world uncertainties.
\end{enumerate}

% Central goals of computational perception is to get structured description of scenes from measurements such as photographic images, scans and videos.
% Computer Vision as Inverse Graphics is the most rational formulations that could help us achieve this goal.

% In the past, it has been hard to directly solve these problems in practice because of computational limitations.

% However, it may be right time to take another look at this idea due to significant advances in deep learning for computer vision, probabilistic programming, and computer graphics.

% Probabilistic programming - a tool that allows us to implement complex models while keeping ability to perform inference, extend with other probabilistic models by being general-purpose.

% Re-formalizing inverse graphics in terms of probabilistic programming and deep learning allow us to solve even more complicated vision problems with off-the-shelf computational technology.

% To make this approach scalable, my research can incorporate effective techniques such as: approximate Bayesian computation, differentiable programming for rendering.

Computer Graphics nowadays seems to be improving at a great pace in terms of designing solutions for hard image synthesis problems, but these solutions are usually hand-made and not flexible enough to cover all needs for general-purpose real world object generating, latest advances in generative models can help with that.

For more detailed review of 3D scene generation and analysis you can see~\cite{2017arXiv170609577M}.

Great paper by Rezende et.al.~\cite{rezende2016unsupervised} about estimating 3D object shape as hidden layer in network presented with multiple 2D projections of an object, showed that in different encodings of 3D shapes such as voxels and mesh with fixed number of vertices you can still recover without actively providing camera coordinates of those projections. 

Attend-Infer-Repeat paper~\cite{eslami2016attend} describes an architecture which essentially is a modified sequential auto-encoder~\cite{gregor2015draw} with variable number of latent vectors for different objects in an input sample, it is achieved by using Dirichlet Process prior. It potentially provides an ability to model scenes as a mixture of distributions with different amount of uncertainty and even capturing "new classes" of objects.

Work on creating probability distribution for shapes is not new, a good example of that is 3DShapeNet~\cite{wu20153d} paper which besides introducing ModelNet large-scale shape dataset also showed that it's possible to make a multi-layer convolutional Restricted Boltzman Machine that can perform forward and back inference, shape completion and next best view estimation.

Neural Networks can also be used to implicitly encode a probability distribution in auto-encoder like architecture as seen in \cite{dai2016shape,kulkarni2015deep,gwak2017weakly} but with some adjustment to encodings one can also encode texture, like in work by Tatarchenko et.al~\cite{tatarchenko2016multi}.

For specific sub-domain like "bedrooms" with know sophisticated generators like CAD rendering engine in IM2CAD~\cite{Izadinia_2017_CVPR} paper, estimating properties of scenes is done with direct optimization or a MCMC methods. 

New approaches to use Neural Networks to create meshes also emerging: like SurfNet~\cite{Sinha_2017_CVPR}. A lot of works by M. Bronstein attacks a problem of applying deep learning to a surface decomposition problem, for more details see a comprehensive review~\cite{2016arXiv161108097B}.

A lot of researchers over the last 20 years came to the idea that scenes and images are better represented as discrete structures with relational and hierarchical properties. 
New datasets that make explicit relations on visual objects were created recently \cite{krishna2017visual}, spurring new research in scene graphs \cite{DBLP:journals/corr/abs-1804-01622,Xu_2017_CVPR}.
For example Mumford and Zhu in \cite{zhu2006stochastic}, discussed that spatial scenes can have a "grammar" on spatial objects and geometric primitives.
Inverse Graphics as a paradigm of computer vision is quite old, but it started getting popular again as the result of advancements in deep learning and computer graphics. In \cite{wu2017neural} problem of obtaining a parametric description of a synthetic scene is achieved through hourglass-like encoder-decoder architecture, where graphics engine takes place of the encoder, we utilize a similar approach.
Two very similar recent papers SPIRAL \cite{pmlr-v80-ganin18a} and Canvas-Drawer networks \cite{frans2018unsupervised} provide a method to generate a sequence of actions in graphical editing software resulting in an image, but those separate actions (brush strokes) are not manipulate and don't provide a way to disentangle topological and style properties. 
In recent years multiple groups started using deep learning to approach inverse graphics task \cite{ellis2018learning,Tulsiani_2017_CVPR}.
The main difference of our work is two-fold: 1) we model probabilistic distribution on space of annotated graphs and therefore on space of graphical programs, and 2) because we use geometric graphs as a representation of data we can define different primitives that require a variable amount of keypoints. Our compressed representation captures semantic and spatial information at the same time.
One of the papers dealt with a problem of modeling images as a hierarchy of sub-parts of some nature  \cite{russell2009associative}, or as a tree of geometric primitives (e.g. cylinders, spheres or 3D boxes) \cite{li2017grass}.

The problem of analyzing point clouds was developed by multiple groups over the last three years; the best known of them is PointNet family of models (\cite{qi2016pointnet,qi2017pointnet++}), developed at Stanford.
Because rendering is a surjective operation, obtaining its inverse is an ill-posed problem; thus, numerically solving it might lead to instability in learning observed in \cite{tian2018learning}. That is why modeling it as a probability distribution can be beneficial, finding a program to represent incomplete shape can have multiple modes, e.g., multiple likely solutions that have input as a projection. Works that deal with that are \cite{kulkarni2014inverse,wu20153d,kulkarni2015picture}.