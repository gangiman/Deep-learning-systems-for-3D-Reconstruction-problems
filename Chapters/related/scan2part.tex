% !TEX root = ../../Thesis_main.tex
\section{Part-aware Reconstruction}
\label{sec:part_reconstruction}

About inductive bias and an ability to construct complicated objects from parts, adding hierarchy to scene ontology.

\subsection{Deep learning for 3d scene understanding}
\label{related:scene-understanding}
Deep learning has been applied for semantic 3D scene understanding in a variety of ways, and we only review the core work related to the semantic and instance segmentation of 3D scenes. 
Most relevant to our work, deep learning approaches have been used on 3D reconstructions of scenes represented by \emph{3D volumetric grids} ~\cite{dai2017scannet,dai20183dmv,hou20193d,liu2019masc}. For volumetric grid, 3D convolutions may be defined analogously to 2D convolutions in image domains, giving rise to 3D convolutional neural nets (3D CNNs).
\cite{dai20183dmv} uses auxiliary color information, 
Memory requirements have been addressed by adaptive data structures~\cite{wang2017cnn}.
Similar to this body of work, we operate on volumetric representations of 3D scenes, but perform parts-based segmentation. % Additionally, we differ by only operating on raw scan geometry without any auxiliary information such as RGB.

Methods operating on raw point clouds provide an alternative to volumetric 3D CNNs by constructing an appropriate operations directly on \emph{unstructured point clouds} for a variety of applications including semantic labeling (e.g.,~\cite{qi2017pointnet,qi2017pointnet++,klokov2017escape,wang2018sgpn,wang2019dynamic}). Most recently, instance~\cite{elich20193d,liang20193d,elich20193d,yi2019gspn,yang2019learning,zhang2019point,engelmann20203d} and joint semantic-instance~\cite{wang2019associatively,pham2019jsis3d} segmentation tasks on point clouds have been considered closely. While point-based methods require less computations, learning with irregular structures such as point clouds is challenging.
%and does not allow differentiating between empty and occluded space.
To segment instances, recently proposed volumetric and point-based approaches use metric learning  to extract per-point embeddings that are subsequently grouped into object instances~\cite{elich20193d,yi2019gspn,lahoud20193d,liu2019masc}. We take advantage of this mechanism in our bottom-up instance segmentation.

% 2) going beyond objects/instances: hierarchical and part-based 
% Hierarchical segmentation gives better results even without explicit parts learning \cite{Tao2020HierarchicalMA}

Part-aware methods for learning  focus on meshes or complete, clean point clouds constructed from 3D CAD models. The most closely related work  is semantic parts labeling (e.g.,~\cite{yi2016scalable,wang2017cnn,qi2017pointnet,mo2019partnet,yi2019gspn,zhang2019point}) and part instance segmentation~\cite{zhang2019point} for voxelized or point-sampled 3D shapes. Other works focus on leveraging parts structure of clean shapes for co-segmentation~\cite{chen2019bae,zhu2019cosegnet}, hierarchical mesh segmentation~\cite{yi2017learning}, shape assembly/generation~\cite{mo2019structurenet,wu2019sagnet,wu2019pq,mo2020pt2pc}, geometry abstraction~\cite{russell2009associative,li2017grass,sun2019learning}, and other applications.

There is also exist work that attempts to perform hierarhical part decomposition for 3D shapes by mesh segmentation~\cite{yi2017learning}. In setting where part labels are less precise and correspond as tags to objects 3D CNN on volumes for part discovery can be used~\cite{muralikrishnan2018tags2parts}.

Hierarchical part structure of objects can be effectevly represented in latent space, in \cite{mo2019structurenet} model learns a latent space for 3D shape parts enabling shape generation, allows for part editing, but it's unclear if all these properties will generalize because there was only a single non-semantic experiment on real-world data. In a follow up paper \cite{mo2020structedit} model computes embeddings for shape differences for fine-grained shape manipulation, however again the paper focuses on graph structure of sampled objects shape not on 3D sensor data.

SagNet \cite{wu2019sagnet} is similar to \cite{mo2019structurenet} because it performs part-aware shape generation but uses medium of voxels instead of point clouds,

Another approach to introduce structural knowledge into a model is to perform reconstruction by assembling parts, either representing them as separate shapes or some geometric primitive like 3D Boxes, in PQ-Net~\cite{wu2020pq} it's shown that this approach can work pretty well.

% luo2020learning - focusess on bottom-up segmentation of shapes from unseen categories
% mo2020pt2pc 3D shape generation from part trees
% sun2019learning abstract parts geometry by cuboids

In comparison, our focus is on learning part-based semantic and instance segmentation of noisy and fragmented real-world 3D scans. 

Other methods have been studied in the context of 3D scene segmentation, such as complementing CNNs with conditional random fields~\cite{pham2019jsis3d,pham2019real,wang2017cnn}, however, these are beyond the scope of this paper.


\subsection{Assembly from parts and hierarchy}
A lot of researchers over the last 20 years came to the idea that scenes and images are better represented as discrete structures with relational and hierarchical properties.
New datasets that make explicit relations on visual objects were created recently \cite{krishna2017visual}, spurring new research in scene graphs \cite{DBLP:journals/corr/abs-1804-01622,Xu_2017_CVPR} and reconstruction. 
In cognitive science, it have been conjectured for a long time that ability to compose complex objects and scenes from parts is a fundamental part of human perception \cite{hoffman1984parts,biederman1987recognition}. The concept of "Recognition-by-components" is closely related to "analysis-by-synthesis" \cite{yuille2006vision,yildirim2015efficient} approach in machine learning. 
Mumford and Zhu in \cite{zhu2006stochastic} assume that spatial scenes can be defined by a "grammar" of spatial objects and geometric primitives, similar to sentences in natural language, where a sequence of words can have multiple parsing trees providing multiple explanations to single sentence. Multiple solutions are expected because solving an under-constrained inverse problem (in this case inverse graphics problem) can have multiple solutions. The solution can be made unique either with stronger priors or can be resolved in downstream processing if uncertainty is propagated.
% Modeling images as a hierarchy of sub-parts  or as a tree of geometric primitives (e.g. cylinders, spheres or 3D boxes) was considered in \cite{russell2009associative,li2017grass}.

% \textcolor{blue}{VI: где-то должен быть жирный кусок текста, чётко объясняющий, почему мы в статье не сравниваемся ни с одним конкурентом, даже тривиальными собственно придуманными, например: партнет, которому на вход подаётся pc. Точка pc = центр вокселя}

